{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "081068e2-4c5c-45db-8ba7-9193f9a4dfe9",
   "metadata": {},
   "source": [
    "# Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5729d01-144b-45ec-940a-c5b3bfa6fe5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf # Daily trading data\n",
    "import pandas as pd\n",
    "from prophet import Prophet # For Forecast\n",
    "from datetime import datetime\n",
    "\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from serpapi import GoogleSearch # For News report\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37029a5e-48cb-4e68-a392-5ef0fb8e5fbd",
   "metadata": {},
   "source": [
    "# SET UP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dec072-1339-4737-9b5b-93a35937ee09",
   "metadata": {},
   "source": [
    "## Initialize the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c72920a-df8e-4146-a854-99013fa2a8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET UP\n",
    "\n",
    "# Define tickers\n",
    "tickers = {\n",
    "    \"Meta\": \"META\",\n",
    "    \"Amazon\": \"AMZN\",\n",
    "    \"Netflix\": \"NFLX\",\n",
    "    \"Google\": \"GOOGL\",\n",
    "    \"NVIDIA\": \"NVDA\"\n",
    "}\n",
    "\n",
    "# Date range for 5 years\n",
    "start_date = \"2018-08-01\"\n",
    "#start_date = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "end_date = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# Dates to forecast\n",
    "forecast_dates = [\n",
    "    '2025-08-31',\n",
    "    '2025-12-31',\n",
    "    '2026-08-31',\n",
    "    '2026-12-31',\n",
    "    '2027-08-31',\n",
    "    '2027-12-31'\n",
    "]\n",
    "\n",
    "# for google search from serpapi\n",
    "SERPAPI_KEY =  \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a126ac2-87c0-4e12-9d17-dfc7d5e78962",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3304d3d6-b98d-4344-a3c5-a7d5d86d0fdb",
   "metadata": {},
   "source": [
    "### Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11bdcab6-a417-44c3-866e-3d1453af083e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def forecast_stock(name, ticker,df):\n",
    "    \"\"\"\n",
    "    Forecasting stock prices for the target dates using Prophet. \n",
    "    \n",
    "    Parameters:\n",
    "        name   : Name of the company.\n",
    "        Ticker : abbreviation of the company by which it is uniquely identified.\n",
    "        df     : the dataframe which contains the time series data\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Forecasted values over the entire period.\n",
    "    \"\"\"\n",
    "    print(f\"\\nüìà Forecasting for {name} ({ticker})\")\n",
    "    df = df[['Date','Close']].dropna()#.reset_index()  # drop NaNs and reset index\n",
    "    \n",
    "    # Prepare for Prophet\n",
    "    df.columns = ['ds', 'y']\n",
    "    df['y'] = pd.to_numeric(df['y'], errors='coerce')\n",
    "    df = df.dropna(subset=['y'])\n",
    "\n",
    "    # Check for sufficient data\n",
    "    if df.shape[0] < 30:\n",
    "        print(\"‚ùå Not enough data for forecasting.\")\n",
    "        return None\n",
    "    \n",
    "    # Fit Prophet\n",
    "    model = Prophet(daily_seasonality=True)\n",
    "    model.fit(df)\n",
    "\n",
    "    # Forecast for next ~900 days\n",
    "    future = model.make_future_dataframe(periods=900)\n",
    "    forecast = model.predict(future)\n",
    "\n",
    "    # Display forecast for forecast dates given in the initial set up\n",
    "    forecast['ds'] = pd.to_datetime(forecast['ds']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "    for target_date in forecast_dates:\n",
    "        row = forecast[forecast['ds'] == target_date]\n",
    "        if not row.empty:\n",
    "            print(f\"{target_date}: ${row['yhat'].values[0]:.2f}\")\n",
    "        else:\n",
    "            print(f\"{target_date}: ‚ùå No forecast (outside prediction range)\")\n",
    "    return forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49861494-a9f7-4aff-8f71-c08bc2799e5a",
   "metadata": {},
   "source": [
    "### Spike Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53ef173b-1967-4832-b7bd-16c1c7d667f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spike Detection Function\n",
    "\n",
    "def detect_price_spikes(df, threshold = 0.05):\n",
    "    \"\"\"\n",
    "    Detects rows where the daily percentage change in closing price exceeds a threshold (up or down).\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame with at least a 'Close' column.\n",
    "        threshold (float): The percentage change threshold to consider a spike (e.g., 0.05 = 5%).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Subset of the original DataFrame with significant changes.\n",
    "    \"\"\"\n",
    "    df['pctchange'] = df['Close'].pct_change()\n",
    "    spikes = df[abs(df['pctchange']) > threshold]\n",
    "    return spikes[['Date', 'Close', 'pctchange']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8891e1-8531-4682-a256-d9ac2fae220a",
   "metadata": {},
   "source": [
    "### Scraper: FAANG stock spike headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc6da722-0936-4149-b1f0-f2eace4a0ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraper  with a limit to headlines and also relevancy\n",
    "\n",
    "def get_news_headlines(company, date, limit = 5, keywords = None):\n",
    "    \"\"\"\n",
    "    Searches and scrapes news headlines using GoogleNews via SerpAPI related to each spike that happened.\n",
    "    \n",
    "    Parameters:\n",
    "        company : str - Name of the company.\n",
    "        date    : The Date (YYYY-MM-DD) to search for news.\n",
    "        limit   : int  - Max number of articles to return.\n",
    "        keyword : List - List of relevant keywords to filter articles.\n",
    "\n",
    "    Returns:\n",
    "        List : list of headlines with title, link, source, etc.\n",
    "    \"\"\"\n",
    "    if keywords is None:\n",
    "        keywords = [\"stock\", \"price\", \"earnings\", \"forecast\", \"revenue\", \"market\"]\n",
    "    \n",
    "    params = {\n",
    "        \"engine\": \"google_news\",\n",
    "        \"q\": f\"{company} stock price OR earnings\",\n",
    "        \"api_key\": SERPAPI_KEY,\n",
    "        \"hl\": \"en\",\n",
    "        \"gl\": \"us\",\n",
    "        \"from\": date,\n",
    "        \"to\": date\n",
    "    }\n",
    "\n",
    "    search = GoogleSearch(params)\n",
    "    results = search.get_dict()\n",
    "    articles = results.get(\"news_results\", [])\n",
    "    \n",
    "    headlines = []\n",
    "    for article in articles:\n",
    "        title = article.get(\"title\", \"\")\n",
    "        if any(kw.lower() in title.lower() for kw in keywords):\n",
    "            link = article.get(\"link\", \"\")\n",
    "            source = article.get(\"source\", \"\")\n",
    "            headlines.append({\"company\": company, \"date\": date, \"title\": title, \"link\": link, \"source\": source})\n",
    "        if len(headlines) >= limit:\n",
    "            break\n",
    "\n",
    "    return headlines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7432de40-0aad-43d8-876b-d6084f9a273f",
   "metadata": {},
   "source": [
    "# Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b454bb74-95a3-433e-a616-340e1ec3ecfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "for name, ticker in tickers.items():\n",
    "    df = yf.download(ticker, start=start_date, end=end_date,auto_adjust=True)\n",
    "    df.reset_index(inplace=True)\n",
    "    df.columns = ['_'.join(col).strip() if isinstance(col, tuple) else col for col in df.columns]\n",
    "    column_name= (df.columns).to_list()\n",
    "    new_column = [x.split('_')[0] for x in column_name] # strip of the ticker in the column name\n",
    "    df.columns= new_column\n",
    "    filename = f'{name}.csv'\n",
    "    df.to_csv(filename, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31501e9c-b37c-4cc7-b201-47044310d4c1",
   "metadata": {},
   "source": [
    "# Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7601df4b-827b-47ff-ab6d-aa67f85bc8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Forecasting for Meta (META)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:21:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:21:09 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-31: $724.67\n",
      "2025-12-31: $761.17\n",
      "2026-08-31: $895.27\n",
      "2026-12-31: $934.49\n",
      "2027-08-31: $1068.72\n",
      "2027-12-31: $1107.72\n",
      "\n",
      "üìà Forecasting for Amazon (AMZN)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:21:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:21:10 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-31: $230.04\n",
      "2025-12-31: $235.66\n",
      "2026-08-31: $264.73\n",
      "2026-12-31: $270.56\n",
      "2027-08-31: $299.68\n",
      "2027-12-31: $305.37\n",
      "\n",
      "üìà Forecasting for Netflix (NFLX)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:21:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:21:12 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-31: $1221.53\n",
      "2025-12-31: $1390.23\n",
      "2026-08-31: $1704.47\n",
      "2026-12-31: $1871.52\n",
      "2027-08-31: $2186.77\n",
      "2027-12-31: $2351.02\n",
      "\n",
      "üìà Forecasting for Google (GOOGL)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:21:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:21:14 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-31: $186.83\n",
      "2025-12-31: $189.43\n",
      "2026-08-31: $203.84\n",
      "2026-12-31: $207.20\n",
      "2027-08-31: $221.64\n",
      "2027-12-31: $225.10\n",
      "\n",
      "üìà Forecasting for NVIDIA (NVDA)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:21:15 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:21:16 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-31: $158.88\n",
      "2025-12-31: $169.96\n",
      "2026-08-31: $201.94\n",
      "2026-12-31: $213.34\n",
      "2027-08-31: $245.20\n",
      "2027-12-31: $256.46\n"
     ]
    }
   ],
   "source": [
    "for name, ticker in tickers.items():\n",
    "    filename = f'{name}.csv'\n",
    "    df = pd.read_csv(filename,index_col=0)\n",
    "    forecast_stock(name, ticker, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784b8abe-0e8f-4f4f-9a87-7480317e1244",
   "metadata": {},
   "source": [
    "# Stock Spike Detection and News Headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67c13863-3388-4568-8238-f39d07b62899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Searching news for Meta\n",
      "‚ö†Ô∏è on 2025-04-03 (spike: -8.96%)...\n",
      "‚ö†Ô∏è on 2025-04-04 (spike: -5.06%)...\n",
      "‚ö†Ô∏è on 2025-04-09 (spike: 14.76%)...\n",
      "‚ö†Ô∏è on 2025-04-10 (spike: -6.74%)...\n",
      "‚ö†Ô∏è on 2025-05-12 (spike: 7.92%)...\n",
      "‚ö†Ô∏è on 2025-07-31 (spike: 11.25%)...\n",
      "üîç Searching news for Amazon\n",
      "‚ö†Ô∏è on 2024-08-02 (spike: -8.78%)...\n",
      "‚ö†Ô∏è on 2024-11-01 (spike: 6.19%)...\n",
      "‚ö†Ô∏è on 2025-04-03 (spike: -8.98%)...\n",
      "‚ö†Ô∏è on 2025-04-09 (spike: 11.98%)...\n",
      "‚ö†Ô∏è on 2025-04-10 (spike: -5.17%)...\n",
      "‚ö†Ô∏è on 2025-05-12 (spike: 8.07%)...\n",
      "üîç Searching news for Netflix\n",
      "‚ö†Ô∏è on 2024-10-18 (spike: 11.09%)...\n",
      "‚ö†Ô∏è on 2025-01-22 (spike: 9.69%)...\n",
      "‚ö†Ô∏è on 2025-03-06 (spike: -8.53%)...\n",
      "‚ö†Ô∏è on 2025-04-04 (spike: -6.67%)...\n",
      "‚ö†Ô∏è on 2025-04-09 (spike: 8.62%)...\n",
      "‚ö†Ô∏è on 2025-04-22 (spike: 5.31%)...\n",
      "‚ö†Ô∏è on 2025-07-18 (spike: -5.10%)...\n",
      "üîç Searching news for Google\n",
      "‚ö†Ô∏è on 2024-12-10 (spike: 5.59%)...\n",
      "‚ö†Ô∏è on 2024-12-11 (spike: 5.52%)...\n",
      "‚ö†Ô∏è on 2025-02-05 (spike: -7.29%)...\n",
      "‚ö†Ô∏è on 2025-04-09 (spike: 9.68%)...\n",
      "‚ö†Ô∏è on 2025-05-07 (spike: -7.26%)...\n",
      "üîç Searching news for NVIDIA\n",
      "‚ö†Ô∏è on 2024-08-05 (spike: -6.36%)...\n",
      "‚ö†Ô∏è on 2024-08-07 (spike: -5.12%)...\n",
      "‚ö†Ô∏è on 2024-08-08 (spike: 6.13%)...\n",
      "‚ö†Ô∏è on 2024-08-13 (spike: 6.53%)...\n",
      "‚ö†Ô∏è on 2024-08-29 (spike: -6.38%)...\n",
      "‚ö†Ô∏è on 2024-09-03 (spike: -9.53%)...\n",
      "‚ö†Ô∏è on 2024-09-11 (spike: 8.15%)...\n",
      "‚ö†Ô∏è on 2025-01-07 (spike: -6.22%)...\n",
      "‚ö†Ô∏è on 2025-01-27 (spike: -16.97%)...\n",
      "‚ö†Ô∏è on 2025-01-28 (spike: 8.93%)...\n",
      "‚ö†Ô∏è on 2025-02-05 (spike: 5.21%)...\n",
      "‚ö†Ô∏è on 2025-02-27 (spike: -8.48%)...\n",
      "‚ö†Ô∏è on 2025-03-03 (spike: -8.69%)...\n",
      "‚ö†Ô∏è on 2025-03-06 (spike: -5.74%)...\n",
      "‚ö†Ô∏è on 2025-03-10 (spike: -5.07%)...\n",
      "‚ö†Ô∏è on 2025-03-12 (spike: 6.43%)...\n",
      "‚ö†Ô∏è on 2025-03-14 (spike: 5.27%)...\n",
      "‚ö†Ô∏è on 2025-03-26 (spike: -5.74%)...\n",
      "‚ö†Ô∏è on 2025-04-03 (spike: -7.81%)...\n",
      "‚ö†Ô∏è on 2025-04-04 (spike: -7.36%)...\n",
      "‚ö†Ô∏è on 2025-04-09 (spike: 18.72%)...\n",
      "‚ö†Ô∏è on 2025-04-10 (spike: -5.91%)...\n",
      "‚ö†Ô∏è on 2025-04-16 (spike: -6.87%)...\n",
      "‚ö†Ô∏è on 2025-05-12 (spike: 5.44%)...\n",
      "‚ö†Ô∏è on 2025-05-13 (spike: 5.63%)...\n",
      "‚úÖ News saved to faang_spike_news.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "one_year_ago = (datetime.today()-relativedelta(years=1)).strftime('%Y-%m-%d')\n",
    "all_news = []\n",
    "\n",
    "for name, ticker in tickers.items():\n",
    "    filename = f'{name}.csv'\n",
    "    df = pd.read_csv(filename,index_col=0)\n",
    "    \n",
    "    # Preparing data for Spike detection and scraping by getting data from 1 year ago\n",
    "    ind =list(df[df.Date == one_year_ago].index)[0]\n",
    "    newdf = df.iloc[ind:].reset_index()\n",
    "\n",
    "    # Run spikes detector for each company\n",
    "    spikes = detect_price_spikes(newdf, threshold=0.05)  # daily move > 5%\n",
    "    \n",
    "    if not spikes.empty:\n",
    "        spikefile = f'spike_{name}.csv'\n",
    "        spike_results = spikes[['Date','pctchange']]\n",
    "        spike_results.to_csv(spikefile,index=True)\n",
    "    \n",
    "    # Run scraper for all spikes\n",
    "    print(f\"üîç Searching news for {name}\")\n",
    "    for _,row in spike_results.iterrows():\n",
    "        date = row['Date']\n",
    "        #date=  datetime.strptime(date, '%Y-%m-%d')\n",
    "        print(f\"‚ö†Ô∏è on {date} (spike: {row['pctchange']:.2%})...\")\n",
    "        headlines = get_news_headlines(name, date)\n",
    "        # # Print the headlines\n",
    "        # for news in headlines:\n",
    "        #     print('üìå',news['title'])\n",
    "        all_news.extend(headlines)\n",
    "        time.sleep(2)  # avoid hitting rate limit\n",
    "\n",
    "# Save the headlines to csv file\n",
    "newsdf = pd.DataFrame(all_news)\n",
    "newsdf.to_csv(\"faang_spike_news.csv\", index=False)\n",
    "print(\"‚úÖ News saved to faang_spike_news.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a44c53c-69b3-4125-a036-2b9aea1ee392",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3(faang)",
   "language": "python",
   "name": "faang"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
